{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ukoly\n1. Prevest data do pandas dataframu\n    1. Data jsou ve formatu arff \n2. Navrhnout model a vyhodnotim model","metadata":{}},{"cell_type":"code","source":"from scipy.io import arff\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn","metadata":{"execution":{"iopub.status.busy":"2023-04-24T15:53:33.975442Z","iopub.execute_input":"2023-04-24T15:53:33.975895Z","iopub.status.idle":"2023-04-24T15:53:33.982622Z","shell.execute_reply.started":"2023-04-24T15:53:33.975852Z","shell.execute_reply":"2023-04-24T15:53:33.981314Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"path_arff_train = \"/kaggle/input/heart-beat-classification/AbnormalHeartbeat_TRAIN.arff\"\npath_ts_train = \"/kaggle/input/heart-beat-classification/AbnormalHeartbeat_TRAIN.ts\"\npath_arff_test = \"/kaggle/input/heart-beat-classification/AbnormalHeartbeat_TEST.arff\"\npath_ts_test = \"/kaggle/input/heart-beat-classification/AbnormalHeartbeat_TEST.ts\"","metadata":{"execution":{"iopub.status.busy":"2023-04-24T15:53:34.597955Z","iopub.execute_input":"2023-04-24T15:53:34.598378Z","iopub.status.idle":"2023-04-24T15:53:34.603753Z","shell.execute_reply.started":"2023-04-24T15:53:34.598339Z","shell.execute_reply":"2023-04-24T15:53:34.602413Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"data_arff_train = arff.loadarff(path_arff_train)\ndata_arff_test = arff.loadarff(path_arff_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T15:53:35.007975Z","iopub.execute_input":"2023-04-24T15:53:35.008885Z","iopub.status.idle":"2023-04-24T15:53:42.575890Z","shell.execute_reply.started":"2023-04-24T15:53:35.008840Z","shell.execute_reply":"2023-04-24T15:53:42.574738Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"Inspekce dat\n\nData jsou ve formatu arff. Pro pouziti je nutne je nejprve prevest do numpy pole, ktere je nasledne prevedeno do pandas dataframu.\ndata_arff_train jsou ve formatu touple kde, index 0 obsahuje data a index 1 obsahuje metadata *scipy.io.arff.arffread.MetaData*. Meta data rikaji jakeho typu jsou jednotlive zaznamy. \n\nPodle zadani maji data frekvenci 4KHz.","metadata":{}},{"cell_type":"code","source":"data_train = pd.DataFrame(data_arff_train[0])\nX_train = data_train.iloc[:, :-1]\ny_train = data_train.target\ndata_test = pd.DataFrame(data_arff_test[0])\nX_test = data_test.iloc[:, :-1]\ny_test = data_test.target","metadata":{"execution":{"iopub.status.busy":"2023-04-24T16:40:57.437704Z","iopub.execute_input":"2023-04-24T16:40:57.438866Z","iopub.status.idle":"2023-04-24T16:40:58.021813Z","shell.execute_reply.started":"2023-04-24T16:40:57.438810Z","shell.execute_reply":"2023-04-24T16:40:58.020618Z"},"trusted":true},"execution_count":275,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-24T16:40:58.026462Z","iopub.execute_input":"2023-04-24T16:40:58.026841Z","iopub.status.idle":"2023-04-24T16:40:58.034175Z","shell.execute_reply.started":"2023-04-24T16:40:58.026804Z","shell.execute_reply":"2023-04-24T16:40:58.032838Z"},"trusted":true},"execution_count":276,"outputs":[{"execution_count":276,"output_type":"execute_result","data":{"text/plain":"(205, 18530)"},"metadata":{}}]},{"cell_type":"markdown","source":"# PyTorch kod","metadata":{}},{"cell_type":"code","source":"X_train = torch.tensor(X_train.values, dtype=torch.float32)\ny_train = y_train.apply(lambda x: 1 if x == b'Abnormal' else 0)\ny_train = torch.tensor(y_train.values, dtype=torch.float32)\nX_test = torch.tensor(X_test.values, dtype=torch.float32)\ny_test = y_test.apply(lambda x: 1 if x == b'Abnormal' else 0)\ny_test = torch.tensor(y_test.values, dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T16:40:59.182526Z","iopub.execute_input":"2023-04-24T16:40:59.182977Z","iopub.status.idle":"2023-04-24T16:40:59.196097Z","shell.execute_reply.started":"2023-04-24T16:40:59.182936Z","shell.execute_reply":"2023-04-24T16:40:59.194898Z"},"trusted":true},"execution_count":277,"outputs":[]},{"cell_type":"code","source":"class my_dataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n    \n    def __getitem__(self, i):\n        return self.X[i], self.y[i]\n    \n    def __len__(self):\n        return len(self.X)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T16:41:00.048362Z","iopub.execute_input":"2023-04-24T16:41:00.048754Z","iopub.status.idle":"2023-04-24T16:41:00.055811Z","shell.execute_reply.started":"2023-04-24T16:41:00.048718Z","shell.execute_reply":"2023-04-24T16:41:00.054402Z"},"trusted":true},"execution_count":278,"outputs":[]},{"cell_type":"code","source":"train_dataset = my_dataset(X_train, y_train)\ntrain_dataloader = DataLoader(train_dataset, batch_size=51, shuffle=True)\ntest_dataset = my_dataset(X_test, y_test)\ntest_dataloader = DataLoader(test_dataset, batch_size=45, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T16:41:00.610185Z","iopub.execute_input":"2023-04-24T16:41:00.611138Z","iopub.status.idle":"2023-04-24T16:41:00.618625Z","shell.execute_reply.started":"2023-04-24T16:41:00.611078Z","shell.execute_reply":"2023-04-24T16:41:00.617574Z"},"trusted":true},"execution_count":279,"outputs":[]},{"cell_type":"markdown","source":"Prehled dat","metadata":{}},{"cell_type":"code","source":"x, targets = next(iter(train_dataloader))\nprint(x[0], targets[0])","metadata":{"execution":{"iopub.status.busy":"2023-04-24T16:41:02.767907Z","iopub.execute_input":"2023-04-24T16:41:02.769012Z","iopub.status.idle":"2023-04-24T16:41:02.787310Z","shell.execute_reply.started":"2023-04-24T16:41:02.768966Z","shell.execute_reply":"2023-04-24T16:41:02.786353Z"},"trusted":true},"execution_count":280,"outputs":[{"name":"stdout","text":"tensor([-0.0100, -0.0206, -0.0161,  ..., -0.0082, -0.0070, -0.0060]) tensor(1.)\n","output_type":"stream"}]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(18530, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1),\n        )\n\n    def forward(self, x):\n        return self.linear_relu_stack(x)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-24T16:41:03.577224Z","iopub.execute_input":"2023-04-24T16:41:03.578031Z","iopub.status.idle":"2023-04-24T16:41:03.585513Z","shell.execute_reply.started":"2023-04-24T16:41:03.577988Z","shell.execute_reply":"2023-04-24T16:41:03.584127Z"},"trusted":true},"execution_count":281,"outputs":[]},{"cell_type":"code","source":"learning_rate = 1e-3\nbatch_size = 8\nepochs = 100\n\nmodel = Model()\nloss_fn = nn.BCELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T16:47:18.951511Z","iopub.execute_input":"2023-04-24T16:47:18.952569Z","iopub.status.idle":"2023-04-24T16:47:19.073530Z","shell.execute_reply.started":"2023-04-24T16:47:18.952518Z","shell.execute_reply":"2023-04-24T16:47:19.072239Z"},"trusted":true},"execution_count":303,"outputs":[]},{"cell_type":"code","source":"def train_loop(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    for batch, (X, y) in enumerate(dataloader):\n        # Compute prediction and loss\n        y = y.view(-1, 1)\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        if batch % 100 == 0:\n            loss, current = loss.item(), (batch + 1) * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n\n#train_loop(train_dataloader, model, loss_fn, optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T16:47:19.077122Z","iopub.execute_input":"2023-04-24T16:47:19.077496Z","iopub.status.idle":"2023-04-24T16:47:19.085739Z","shell.execute_reply.started":"2023-04-24T16:47:19.077461Z","shell.execute_reply":"2023-04-24T16:47:19.084259Z"},"trusted":true},"execution_count":304,"outputs":[]},{"cell_type":"code","source":"def test_loop(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    test_loss, correct = 0, 0\n\n    with torch.no_grad():\n        for X, y in dataloader:\n            y = y.view(-1, 1)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred == y).type(torch.float).sum().item()\n\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n\n#test_loop(test_dataloader, model, loss_fn)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T16:47:19.087865Z","iopub.execute_input":"2023-04-24T16:47:19.088287Z","iopub.status.idle":"2023-04-24T16:47:19.101838Z","shell.execute_reply.started":"2023-04-24T16:47:19.088241Z","shell.execute_reply":"2023-04-24T16:47:19.100632Z"},"trusted":true},"execution_count":305,"outputs":[]},{"cell_type":"code","source":"for t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train_loop(train_dataloader, model, loss_fn, optimizer)\n    test_loop(test_dataloader, model, loss_fn)\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2023-04-24T16:47:22.642649Z","iopub.execute_input":"2023-04-24T16:47:22.643375Z","iopub.status.idle":"2023-04-24T16:47:52.866402Z","shell.execute_reply.started":"2023-04-24T16:47:22.643317Z","shell.execute_reply":"2023-04-24T16:47:52.865232Z"},"trusted":true},"execution_count":306,"outputs":[{"name":"stdout","text":"Epoch 1\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 2\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 3\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 4\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 5\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 6\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 7\n-------------------------------\nloss: 21.568628  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 8\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 9\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 10\n-------------------------------\nloss: 29.411764  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 11\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 12\n-------------------------------\nloss: 31.372549  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 13\n-------------------------------\nloss: 19.607843  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 14\n-------------------------------\nloss: 29.411764  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 15\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 16\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 17\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 18\n-------------------------------\nloss: 39.215687  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 19\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 20\n-------------------------------\nloss: 21.568628  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 21\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 22\n-------------------------------\nloss: 37.254902  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 23\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 24\n-------------------------------\nloss: 29.411764  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 25\n-------------------------------\nloss: 11.764706  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 26\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 27\n-------------------------------\nloss: 21.568628  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 28\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 29\n-------------------------------\nloss: 33.333332  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 30\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 31\n-------------------------------\nloss: 21.568628  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 32\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 33\n-------------------------------\nloss: 29.411764  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 34\n-------------------------------\nloss: 33.333332  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 35\n-------------------------------\nloss: 33.333332  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 36\n-------------------------------\nloss: 17.647058  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 37\n-------------------------------\nloss: 15.686275  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 38\n-------------------------------\nloss: 31.372549  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 39\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 40\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 41\n-------------------------------\nloss: 29.411764  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 42\n-------------------------------\nloss: 37.254902  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 43\n-------------------------------\nloss: 21.568628  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 44\n-------------------------------\nloss: 21.568628  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 45\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 46\n-------------------------------\nloss: 19.607843  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 47\n-------------------------------\nloss: 21.568628  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 48\n-------------------------------\nloss: 37.254902  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 49\n-------------------------------\nloss: 29.411764  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 50\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 51\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 52\n-------------------------------\nloss: 31.372549  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 53\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 54\n-------------------------------\nloss: 31.372549  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 55\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 56\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 57\n-------------------------------\nloss: 21.568628  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 58\n-------------------------------\nloss: 33.333332  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 59\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 60\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 61\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 62\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 63\n-------------------------------\nloss: 31.372549  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 64\n-------------------------------\nloss: 31.372549  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 65\n-------------------------------\nloss: 29.411764  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 66\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 67\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 68\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 69\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 70\n-------------------------------\nloss: 17.647058  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 71\n-------------------------------\nloss: 15.686275  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 72\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 73\n-------------------------------\nloss: 31.372549  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 74\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 75\n-------------------------------\nloss: 21.568628  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 76\n-------------------------------\nloss: 13.725491  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 77\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 78\n-------------------------------\nloss: 29.411764  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 79\n-------------------------------\nloss: 33.333332  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 80\n-------------------------------\nloss: 21.568628  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 81\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 82\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 83\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 84\n-------------------------------\nloss: 21.568628  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 85\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 86\n-------------------------------\nloss: 39.215687  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 87\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 88\n-------------------------------\nloss: 29.411764  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 89\n-------------------------------\nloss: 29.411764  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 90\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 91\n-------------------------------\nloss: 35.294117  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 92\n-------------------------------\nloss: 31.372549  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 93\n-------------------------------\nloss: 19.607843  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 94\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 95\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 96\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 97\n-------------------------------\nloss: 25.490196  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 98\n-------------------------------\nloss: 27.450981  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 99\n-------------------------------\nloss: 33.333332  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nEpoch 100\n-------------------------------\nloss: 23.529411  [   51/  204]\nTest Error: \n Accuracy: 73.2%, Avg loss: 33.333333 \n\nDone!\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}